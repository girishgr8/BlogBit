<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;"><img style="display: block; margin-left: auto; margin-right: auto;" src="https://i2.wp.com/scienceblog.com/wp-content/uploads/2019/10/MIT-Supercomputing_0.jpg?fit=639%2C426&amp;ssl=1&amp;is-pending-load=1" alt="Supercomputer analyzes web traffic across entire internet" /></p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">Understanding web traffic patterns at such a large scale, the researchers say, is useful for informing internet policy, identifying and preventing outages, defending against cyberattacks, and designing more efficient computing infrastructure. A paper describing the approach was presented at the recent IEEE High Performance Extreme Computing Conference.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">For their work, the researchers gathered the largest publicly available internet traffic dataset, comprising 50 billion data packets exchanged in different locations across the globe over a period of several years.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">They ran the data through a novel &ldquo;neural network&rdquo; pipeline operating across 10,000 processors of the MIT SuperCloud, a system that combines computing resources from the MIT Lincoln Laboratory and across the Institute. That pipeline automatically trained a model that captures the relationship for all links in the dataset &mdash; from common pings to giants like Google and Facebook, to rare links that only briefly connect yet seem to have some impact on web traffic.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">The model can take any massive network dataset and generate some statistical measurements about how all connections in the network affect each other. That can be used to reveal insights about peer-to-peer filesharing, nefarious IP addresses and spamming behavior, the distribution of attacks in critical sectors, and traffic bottlenecks to better allocate computing resources and keep data flowing.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">In concept, the work is similar to measuring the cosmic microwave background of space, the near-uniform radio waves traveling around our universe that have been an important source of information to study phenomena in outer space. &ldquo;We built an accurate model for measuring the background of the virtual universe of the Internet,&rdquo; says Jeremy Kepner, a researcher at the MIT Lincoln Laboratory Supercomputing Center and an astronomer by training. &ldquo;If you want to detect any variance or anomalies, you have to have a good model of the background.&rdquo;</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">Joining Kepner on the paper are: Kenjiro Cho of the Internet Initiative Japan; KC Claffy of the Center for Applied Internet Data Analysis at the University of California at San Diego; Vijay Gadepally and Peter Michaleas of Lincoln Laboratory&rsquo;s Supercomputing Center; and Lauren Milechin, a researcher in MIT&rsquo;s Department of Earth, Atmospheric and Planetary Sciences.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;"><span style="border: 0px; margin: 0px; padding: 0px; font-weight: bold;">Breaking up data</span></p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">In internet research, experts study anomalies in web traffic that may indicate, for instance, cyber threats. To do so, it helps to first understand what normal traffic looks like. But capturing that has remained challenging. Traditional &ldquo;traffic-analysis&rdquo; models can only analyze small samples of data packets exchanged between sources and destinations limited by location. That reduces the model&rsquo;s accuracy.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">The researchers weren&rsquo;t specifically looking to tackle this traffic-analysis issue. But they had been developing new techniques that could be used on the MIT SuperCloud to process massive network matrices. Internet traffic was the perfect test case.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">Networks are usually studied in the form of graphs, with actors represented by nodes, and links representing connections between the nodes. With internet traffic, the nodes vary in sizes and location. Large supernodes are popular hubs, such as Google or Facebook. Leaf nodes spread out from that supernode and have multiple connections to each other and the supernode. Located outside that &ldquo;core&rdquo; of supernodes and leaf nodes are isolated nodes and links, which connect to each other only rarely.</p>
<div class="code-block code-block-6" style="border: 0px; margin: 8px 0px; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff; clear: both;">&nbsp;</div>
<div class="code-block code-block-2" style="border: 0px; margin: 8px auto; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff; text-align: center; clear: both; height: auto !important;"><ins class="adsbygoogle" style="border: 0px; margin: 0px; padding: 0px; text-decoration-line: none; display: inline-block; width: 336px; height: 0px;" data-ad-client="ca-pub-1680599806301730" data-ad-slot="7969258089" data-adsbygoogle-status="done" data-auto-ad-size="true" data-overlap-observer-io="false"><ins id="aswift_2_expand" style="border: none; margin: 0px; padding: 0px; text-decoration-line: none; display: inline-table; height: 0px; position: relative; visibility: visible; width: 336px; background-color: transparent;"><ins id="aswift_2_anchor" style="border: none; margin: 0px; padding: 0px; text-decoration-line: none; display: block; height: 0px; position: relative; visibility: visible; width: 336px; background-color: transparent; overflow: hidden; opacity: 0;"><iframe id="aswift_2" style="border-width: 0px; border-style: initial; margin: 0px; padding: 0px; max-width: 100%; left: 0px; position: absolute; top: 0px; width: 336px; height: 280px; overflow: visible;" name="aswift_2" width="336" height="280" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" allowfullscreen="true"></iframe></ins></ins></ins></div>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">Capturing the full extent of those graphs is infeasible for traditional models. &ldquo;You can&rsquo;t touch that data without access to a supercomputer,&rdquo; Kepner says.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">In partnership with the Widely Integrated Distributed Environment (WIDE) project, founded by several Japanese universities, and the Center for Applied Internet Data Analysis (CAIDA), in California, the MIT researchers captured the world&rsquo;s largest packet-capture dataset for internet traffic. The anonymized dataset contains nearly 50 billion unique source and destination data points between consumers and various apps and services during random days across various locations over Japan and the U.S., dating back to 2015.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">Before they could train any model on that data, they needed to do some extensive preprocessing. To do so, they utilized software they created previously, called Dynamic Distributed Dimensional Data Mode (D4M), which uses some averaging techniques to efficiently compute and sort &ldquo;hypersparse data&rdquo; that contains far more empty space than data points. The researchers broke the data into units of about 100,000 packets across 10,000 MIT SuperCloud processors. This generated more compact matrices of billions of rows and columns of interactions between sources and destinations.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;"><span style="border: 0px; margin: 0px; padding: 0px; font-weight: bold;">Capturing outliers</span></p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">But the vast majority of cells in this hypersparse dataset were still empty. To process the matrices, the team ran a neural network on the same 10,000 cores. Behind the scenes, a trial-and-error technique started fitting models to the entirety of the data, creating a probability distribution of potentially accurate models.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">Then, it used a modified error-correction technique to further refine the parameters of each model to capture as much data as possible. Traditionally, error-correcting techniques in machine learning will try to reduce the significance of any outlying data in order to make the model fit a normal probability distribution, which makes it more accurate overall. But the researchers used some math tricks to ensure the model still saw all outlying data &mdash; such as isolated links &mdash; as significant to the overall measurements.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">In the end, the neural network essentially generates a simple model, with only two parameters, that describes the internet traffic dataset, &ldquo;from really popular nodes to isolated nodes, and the complete spectrum of everything in between,&rdquo; Kepner says.</p>
<p style="border: 0px; margin: 0px 0px 1.1em; padding: 0px; color: #3a3a3a; font-family: sans-serif; font-size: 17px; background-color: #ffffff;">The researchers are now reaching out to the scientific community to find their next application for the model. Experts, for instance, could examine the significance of the isolated links the researchers found in their experiments that are rare but seem to impact web traffic in the core nodes.</p>